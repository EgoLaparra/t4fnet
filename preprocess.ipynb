{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import menpo.io as mio\n",
    "from menpodetect import load_opencv_frontal_face_detector, load_opencv_profile_face_detector\n",
    "from menpowidgets import visualize_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "front = load_opencv_frontal_face_detector()\n",
    "side = load_opencv_profile_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load annotations so we know which person goes with which image\n",
    "annos = pd.DataFrame.from_csv('gold.tsv',header=0,index_col=None,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "height = 150\n",
    "width = 150\n",
    "\n",
    "images = []\n",
    "seen = dict()\n",
    "for fp in glob.glob('./img/*.jpg'):\n",
    "    fn = os.path.basename(fp)\n",
    "    #if annos.loc[annos['file_name'] == fn]['subject_id'].sum() in seen:\n",
    "    #    continue\n",
    "    \n",
    "    # face not seen yet\n",
    "    image = mio.import_image(fp)\n",
    "#     front(image)\n",
    "#     if(image.n_landmark_groups == 0):\n",
    "#         side(image)\n",
    "#     if(image.n_landmark_groups > 0):\n",
    "#         image = image.crop_to_landmarks(image.landmarks.group_labels[0])\n",
    "#     else:\n",
    "    cropwidth = min(image.height, image.width) / 2\n",
    "    h = image.height / 2\n",
    "    w = image.width / 2\n",
    "    image = image.crop((h - cropwidth, w - cropwidth), \n",
    "                        (h + cropwidth, w + cropwidth))\n",
    "    image = image.resize((height, width))\n",
    "    images.append(image)\n",
    "    mio.export_image(image, \"./cropped/\" + fn, \"jpg\", overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41376184.gif couldn't be opened\n"
     ]
    }
   ],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "height = 150\n",
    "width = 150\n",
    "\n",
    "pre = \"./overweightPictures/*.\"\n",
    "files_grabbed = flatten([glob.glob(e) for e in [pre+'jpg', pre+'jpeg', pre+'png', pre+'gif']])\n",
    "for fp in files_grabbed:\n",
    "    fnWithExtension = os.path.basename(fp)\n",
    "    fn = os.path.splitext(fnWithExtension)[0]\n",
    "    image = mio.import_image(fp)\n",
    "    try:\n",
    "        cropwidth = min(image.height, image.width) / 2\n",
    "        h = image.height / 2\n",
    "        w = image.width / 2\n",
    "        image = image.crop((h - cropwidth, w - cropwidth), \n",
    "                            (h + cropwidth, w + cropwidth))\n",
    "        image = image.resize((height, width))\n",
    "        mio.export_image(image, \"./croppedTwitter/\" + fn + \".jpg\", \"jpg\", overwrite=True)\n",
    "    except AttributeError:\n",
    "        print(fnWithExtension + \" couldn't be opened\")\n",
    "\n",
    "\n",
    "#visualize_images(images[0::100])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
